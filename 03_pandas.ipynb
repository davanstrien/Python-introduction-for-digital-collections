{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üêº Pandas for working with collections data\n",
    "\n",
    "The aim of this notebook is to show that based on concepts we have seen in previous notebooks we can already do quite a lot. It might not be possible to follow every step but you should see parallels with what we've already seen.  \n",
    "\n",
    "We will use the [newspaper title list](https://bl.iro.bl.uk/work/7da47fac-a759-49e2-a95a-26d49004eba8) as our example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas? \n",
    "\n",
    "Pandas is a tool for working with tabular data in Python. \n",
    "\n",
    "### Why Pandas?\n",
    "Why work with tabular data in Python pandas and not in excel? \n",
    "### Why not Pandas?\n",
    "Are there reasons we might not work with Pandas? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading our data\n",
    "\n",
    "First thing we'll need to do is find a link we can use to download our data. \n",
    "\n",
    "https://bl.iro.bl.uk/work/7da47fac-a759-49e2-a95a-26d49004eba8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://bl.oar.bl.uk/fail_uploads/download_file?fileset_id=67b25f41-a682-4c1f-bf42-550e06b48244'\n",
    "r = requests.get(url)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving \n",
    "\n",
    "We now need to save the response file. We'll do this slightly differently to last time using ```with```. This is a common pattern in Python but we won't spend to much time worrying about why this is better than our previous version now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('title_list.zip', 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to unzip?\n",
    "\n",
    "We now have a zip file. How could we unzip this? We could look for a python library for doing this. An alternative option we have in a notebook environment is to use bash commands. We can run these by using ```!``` in front of the bash command. Sometimes there is a tool in bash which makes something very quick and we may want to just this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip title_list.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can us ```ls``` to check what changed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ```head``` to preview our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 BritishAndIrishNewspapersTitleList_20191118.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening our CSV in Python \n",
    "Now we have our CSV file how do we open this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = 'BritishAndIrishNewspapersTitleList_20191118.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try using ```open()``` and ```read()``` which we previously saw with text files. We'll use the indexing ```[]``` we saw previously to limit how much we see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(csv).read()[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops! Let's try a different encoding. This is something you will come across from time to time. This is one of the things which over time you'll become quicker in debugging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(csv, encoding=\"latin-1\").read()[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to work! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening our CSV in Pandas \n",
    "\n",
    "Now let's try opening our csv in pandas. Some of this will look a bit different to things we've seen before but we'll build on what we've already seen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imported pandas as pd. This is something you'll see sometimes as a way of shortening package names which are often used. You should be careful with this since it can make it less clear to other people what package you are using. In this case ```pd``` is a well established short version of pandas so we can safely use it. \n",
    "\n",
    "How do we load data. Let's try and use the approach we've taken before. We've so far seen that often we have 'read' appear when we are trying to load data. Let's see if that works here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read # tab complete "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could of course also turn to some [documentation](https://pandas.pydata.org/docs/getting_started/intro_tutorials/02_read_write.html#min-tut-02-read-write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably this is the same issue we already saw?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(csv, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! To save us loading data multiple times lets store it in a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we use ```df``` as a variable for storing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a dataframe?\n",
    "\n",
    "A dataframe is used for working with tabular data. There are some similarities with Excel. We'll only scratch the surface of dataframes in this notebook but with a bit of luck you'll get a sense of how to work with them. \n",
    "\n",
    "Let's take a look at the dataframe. As before we can just include a variable in a cell and our notebook will print it for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default pandas won't display all of the rows since this will take up a lot of space on your screen. We can see at the bottom how many rows and columns there are. Often we'll only want to peek at a bit of the data. We can do this using a ```head()``` method on our dataframe variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't seen this before but we may remember seeing ```head``` in the context of bash. We also had ```tail``` so lets see if that works too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting data \n",
    "\n",
    "How do we select data in Pandas? You'll hopefully remember our ```[]``` notation for slicing data. Let's see what slicing in pandas looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country_of_publication']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slightly different from what we saw before but the basic notation looks fairly similar. We can also select multiple columns using a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['country_of_publication','place_of_publication']] # list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we instead use a number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't work but we can make a small change to get this to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting by condition \n",
    "\n",
    "There are lots of other ways of selecting data. We won't cover all of them in this notebook but we'll try and build on the idea of using conditionals as a way of selecting data. \n",
    "\n",
    "## Creating a subset of data\n",
    "As an example use case, let's imagine we're working with a historian who is interested in English newspaper history. To help with this we want to create a subsample of the data which only includes England as the country of publication. \n",
    "\n",
    "Let's take a look at our data again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This gives us one view but we can also directly check columns. We can do this by accessing an attribute of the datafame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an attribute? \n",
    "Again we haven't seen this before but it build on the idea of 'methods' which we saw in previous notebooks (for example ```str.upper()```). You'll notice here we don't have the ```()``` only the dot followed by \"columns\". This is a way of accessing a 'property' of a python object. We won't worry to much about the details of this but an analogy is that for a person they have a height, an age etc. In python for a person we may therefore be able to access these attributes by using ```person.age``` or ```person.height```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to filtering! \n",
    "\n",
    "We can see from above that probably the country of publication is the most relevant thing for us to filter on. How can we do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country_of_publication']=='England'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very similar to the conditions we saw before. What do we get back from calling this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['country_of_publication']=='England')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get something called a \"Series\". This is essentially what each column is in a dataframe. We can see in this case that for each one we get back a Series which says 'true or false' depending on whether our condition is true or not. How can we use this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_england = df['country_of_publication']=='England'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_england"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a variable ```is_england``` which is a Series which contains 'true or false'. Maybe we can now filter using this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[is_england].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! At the moment we're only filtering once. Let's create a new variable to store this filtered version of the dataframe in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_is_england = df[df['country_of_publication']=='England']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check this again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_is_england.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More filtering \n",
    "We now have a dataframe which only contains country of publication which is 'England'. Our historian now tells us that they are only interested in provincial press so they want to exclude London. Let's see if we can no provide a subsample which *exclude* London. To start lets take another look at the columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably place of publication will help us here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['place_of_publication']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be the right column to filter on. We can try a similar approach to before to filter our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_london = df['place_of_publication']!='London'\n",
    "not_london[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to work. Let's have a look at a filtered version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[not_london].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning is often messy!\n",
    "\n",
    "It seems some London is still creeping through. This is because they have been combined with other places so didn't fail or ```!=London``` condition. How can we deal with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save a bit of time we can use dot notation to access the column we're working with. Again this is because in our dataframe each column is an attribute of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index by dot\n",
    "df.place_of_publication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we can use a list to filter out some more of the London rows? We use slightly different notation here but it build on things we've already seen. The new thing here is ```~``` this means exclude in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list\n",
    "london = ['London|Weybridge', 'London']\n",
    "# Check if things from this list appear in our dataframe \n",
    "df.place_of_publication[~df.place_of_publication.isin(london)].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still have London appearing \n",
    "\n",
    "We still have London. We could keep adding in more items to our list to filter on but this is going to get very inefficient. Maybe we can instead check if ```place_of_publication``` contains London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.place_of_publication.contains('London')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh, this doesn't seem to work. This is because we're accessing the series. To use contains we need to be working with 'strings'. Again building on the idea of attributes we can do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.place_of_publication.str.contains('London')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is happening here?\n",
    "We can make it a little bit more explicit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london = df.place_of_publication.str.contains('London', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that contains is using a regular expression to match a condition. This gives you a lot of potential power to filter on complex conditions. Now lets try filtering again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[london]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our friend stackoverflow!\n",
    "https://stackoverflow.com/questions/28311655/ignoring-nans-with-str-contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error is caused because we have some columns where NA appears. Lets fix this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "london = df.place_of_publication.str.contains('London', regex=True, na=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[london]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a filter which works for accessing all of the places where place of publication is London. We can now use this to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~london]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now store this in a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_london = df[~london]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting \n",
    "\n",
    "No we've filtered out London. We can see what places of publication are left. Again we can access attributes and methods. In this case we'll use ```value_counts()``` to count how often a place of publication appears. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_london.place_of_publication.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting?\n",
    "As a quick example we can plot the country of publication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_counts = df_no_london['country_of_publication'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_counts[:10].plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see that we'd need to do some filtering if we wanted to group together the different places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving output \n",
    "No we've filtered out London we want to share the filtered version back to our researcher. We can do this very easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_london.to_csv('no_london.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin \n",
    "\n",
    "This was a very quick tour through Pandas. The aim wasn't to show you everything or give a proper introduction but to try and show you how getting a good grasp on some basic Python concepts quite quickly can extend to doing more complex things. Building confidence in experimenting and debugging will be massively useful to making progress in Python. In particular trying to adapt other peoples notebooks can often get you very far if you only want to change a few things. As an example we could adapt what we have done inn this notebook to filter out only titles published in Scotland or Wales. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
